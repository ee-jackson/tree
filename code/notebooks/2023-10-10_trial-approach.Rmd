---
title: "Trial approach with Mazziotta data"
author: '`r Sys.getenv("USER")`'
date: '`r format(Sys.time(), "%d %B, %Y")`' 
always_allow_html: true
output: 
  github_document:
    keep_html: true
---
	
```{r setup, include = FALSE}
file_name <- rstudioapi::getSourceEditorContext()$path

knitr::opts_chunk$set(
  fig.path =
    paste0("figures/", sub("\\.Rmd$", "", basename(file_name)), "/", sep = "")
)

ggplot2::theme_set(ggplot2::theme_classic(base_size = 10))
```

```{r packages, message=FALSE, warning=FALSE}
library("tidyverse")
library("here")
library("janitor")
library("rsample")

set.seed(123)
```

In this document I'm going to start coding up the main
[approach](https://docs.google.com/document/d/1chDZ_8jM--HWPw2ElIUY2otEej0tJ42KKE3TMrgGMpA/edit#heading=h.mh4gg5x4o2y5) 
using data from [Mazziotta et al. 2022](https://doi.org/10.1111/gcb.16364) whilst we're waiting for the full dataset.

```{r data, message=FALSE}
read_csv(here("data", "raw", "mazziotta","NFI_Projections_CCMS_climate.csv")) %>% 
  clean_names() -> maz_dat

glimpse(maz_dat)
```

In this data there should be 29,892 unique plots. 
Where period is `0`, the data are actually observed and the time periods (`1` to `18`) are predictions from Heureka under three different climate scenarios and four different climate change mitigation solutions (every combination of each).

As part of the climate change mitigation solutions, they also predicted the forest management that would be used for each plot (`forest_domain_data_treatment_control_category`). For each NFI plot and time step, a large number of management activities (such as thinning and clear felling) are simulated, that in sequence constitute different treatment schedules. Then the optimal treatment schedule for each plot is selected based on an objective function and possible constraints.

For what we're doing now I think we only need two management options per plot.

```{r}
summary(as.factor(maz_dat$forest_domain_data_treatment_control_category))
```

Let's filter the data to only include plots that have predictions for both `SetAside (Unmanaged)` and `BAU - NoThinning`.

```{r}
maz_dat %>% 
  filter(forest_domain_data_treatment_control_category == "SetAside (Unmanaged)" |
           forest_domain_data_treatment_control_category == "BAU - NoThinning") ->  maz_dat_bau_sa

maz_dat_bau_sa %>% 
  group_by(id) %>% 
  summarise(n = n_distinct(forest_domain_data_treatment_control_category),
            .groups = "drop") %>% 
  filter(n == 2) %>% 
  select(id) -> plot_list

maz_dat_bau_sa %>% 
  filter(id %in% plot_list$id) -> test_plots

```

We aim to predict individual-level treatment effects (ITE) using meta-learner algorithms. 
We can evaluate the impact of various **decisions** on predictive accuracy.

## Decision 1 - Assignment of NFI plots to a realised management regime

i.e., whether plot is treatment or control

- Option 1 = Random assignment
- Option 2 = Something more realistic, e.g. a spatial constraint

[Data exists](http://www.diva-portal.org/smash/get/diva2:1563052/FULLTEXT01.pdf) on the % of forests in different land use categories for each region of Sweden (Northern, South-Northern, Mid and Southern).
We could use these to assign NFI plots to a management regime.
The Mazziotta data has a `region2` variable:

```{r}
test_plots %>% 
  distinct(region2)
```

But, there are 6 regions here (rather than 4 as in the land use data).
There is a map in the [Heureka wiki](https://www.heurekaslu.se/wiki/Heureka_Wiki) which shows the regions according to Swedish NFI definition.

![](https://www.heurekaslu.se/w/images/thumb/b/b9/Regioner.png/560px-Regioner.png)

This map defines the regions slightly differently to the [land use data](http://www.diva-portal.org/smash/get/diva2:1563052/FULLTEXT01.pdf) but I think we can say that

- 1 is Northern with 12% unmanaged set-asides
- 2 is South-Northern with 12.5% unmanaged set-asides
- 3 is Mid with 8.5% unmanaged set-asides
- 4 and 5 are Southern regions with 7% unmanaged set-asides

For each region we want we want the % of plots randomly selected for set-aside to match the percentages above.

```{r}
test_plots %>% 
    select(id, region2) %>% 
    distinct() -> id_list

assign_group_weighted <- function(region, proportion, data = id_list) {
  data %>% 
    filter(region2 == region) %>% 
    slice_sample(prop = proportion)
}

tibble(region = 1:5,
       proportion = c(0.12, 0.125, 0.085, 0.07, 0.07)) -> weights

pmap(weights, assign_group_weighted) %>% 
  bind_rows() -> set_aside_ids

semi_join(test_plots, set_aside_ids, by = c("id", "region2")) %>% 
  mutate(real_manage = "set_aside") -> set_aside_df

anti_join(test_plots, set_aside_ids, by = c("id", "region2")) %>% 
  mutate(real_manage = "bau") -> bau_df

bind_rows(bau_df, set_aside_df) -> assigned_data
```

```{r assign-weighted}
assigned_data %>% 
  select(id, region2, real_manage) %>% 
  distinct() %>% 
  ggplot(aes(x = region2, fill = real_manage)) +
  geom_bar(stat = "count") +
  ggtitle("Assignment based on region")

```

```{r assign-random}
id_list %>% 
  slice_sample(prop = 0.5) %>% 
  mutate(real_manage = "set_aside") -> set_aside_ids_rand

semi_join(test_plots, set_aside_ids_rand, by = c("id", "region2")) %>% 
  mutate(real_manage = "set_aside") -> set_aside_df_rand

anti_join(test_plots, set_aside_df_rand, by = c("id", "region2")) %>% 
  mutate(real_manage = "bau") -> bau_df_rand

bind_rows(bau_df_rand, set_aside_df_rand) -> assigned_data_rand

assigned_data_rand %>% 
  select(id, region2, real_manage) %>% 
  distinct() %>% 
  ggplot(aes(x = region2, fill = real_manage)) +
  geom_bar(stat = "count") +
  ggtitle("Random assignment to groups")
```


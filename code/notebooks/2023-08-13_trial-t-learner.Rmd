---
title: "T-learner test run"
author: '`r Sys.getenv("USER")`'
date: '`r format(Sys.time(), "%d %B, %Y")`' 
always_allow_html: true
output: 
  github_document:
    keep_html: true
---
	
```{r setup, include = FALSE}
file_name <- rstudioapi::getSourceEditorContext()$path

knitr::opts_chunk$set(
  fig.path =
    paste0("figures/", sub("\\.Rmd$", "", basename(file_name)), "/", sep = "")
)

ggplot2::theme_set(ggplot2::theme_classic(base_size = 10))
```

Today I'm going to quickly re-build the s-learner I made [here](2023-07-26_trial-s-learner.md) because it was rubbish and I realised I had left out the `alturism` variable. Then I'll have a go at building a t-learner, and then compare them!

```{r packages, message=FALSE, warning=FALSE}
library("tidyverse")
library("tidymodels")
library("vip")
library("here")
library("janitor")
library("patchwork")

set.seed(123)
```

```{r}
raw_data <- read_csv(here::here("data", "raw", "soga_gaston_data.csv"))

glimpse(raw_data)
```

## Refactoring the data

```{r fig.height=10, fig.width=10, message=FALSE, warning=FALSE}

raw_data %>% 
  clean_names() %>%
  rename(childhood_nature = frequency_of_nature_experiences_childhood, 
         urban = degree_of_urbanisation,
         altruism = altruistic_value_orientation,
         pro_biodiversity = probability_of_adopting_pro_biodiversity_behaviour_number_3,
         recent_nature = frequency_of_nature_experiences_recent) %>% 
  select(-contains("probability")) %>% 
  mutate(recent_nature = case_when(recent_nature == 1 |
                                     recent_nature == 2 ~ 0,
                                   .default = 1) ) %>% 
  mutate(across(c(childhood_nature, urban, income, education_level),
                as.ordered)) %>% 
  mutate(across(c(recent_nature, pro_biodiversity, gender),
                as.factor)) %>% 
  
  drop_na() %>% 
  mutate(id = paste0("A", row_number(), sep = "")) %>% 
  select(id, pro_biodiversity, recent_nature, income, childhood_nature, 
         gender, education_level, urban, altruism) -> tidy_data
  
glimpse(tidy_data)  

```

## S-learner

### train

```{r}
data_split <- initial_split(tidy_data, prop = 1/3)
train_data_s <- training(data_split)
test_data_s <- testing(data_split)

rand_forest(
  mode = "classification",
  engine = "ranger"
) -> rf_def

rf_def %>% 
  fit(
    pro_biodiversity ~ recent_nature + 
      income + childhood_nature  + gender  + education_level + urban + altruism,
    data = train_data_s
  ) -> s_train_fit

s_train_fit

```

### test

```{r}
predict(s_train_fit, test_data_s, type = "prob") %>% 
  bind_cols(test_data_s) -> s_result

glimpse(s_result)

s_result %>% 
  roc_curve(pro_biodiversity, .pred_0) %>% 
  ggplot(aes(x = 1 - specificity, y = sensitivity)) + 
  geom_path(lwd = 1.5, alpha = 0.8) +
  geom_abline(lty = 3) + 
  coord_equal()
```

### tune

```{r}
rf_tune <- rand_forest(mtry = tune(), min_n = tune()) %>%
  set_engine("ranger", num.threads = 3) %>%
  set_mode("classification")

rf_tune

```

```{r}
finalize(mtry(), select(train_data_s, -id, - pro_biodiversity))

tree_grid <- grid_regular(mtry(c(1, 6)),
                          min_n(),
                          levels = 5)
```

Run models with range of chosen hyperparameters

```{r}
rf_recipe <- recipe(data = train_data_s,
                    formula = pro_biodiversity ~ recent_nature +
                      income + childhood_nature  + gender  + 
                      education_level + urban + altruism)

rf_workflow <- workflow() %>%
  add_recipe(rf_recipe) %>%
  add_model(rf_tune)

# create a set of cross-validation resamples to use for tuning
trees_folds <- vfold_cv(train_data_s, v = 25)

rf_tune_res <- 
  tune_grid(rf_workflow,
            resamples = trees_folds,
            grid = tree_grid,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(roc_auc))

```


```{r}
rf_tune_res %>%
  collect_metrics() %>%
  filter(.metric == "roc_auc") %>%
  mutate(min_n = factor(min_n)) %>%
  ggplot(aes(mtry, mean, color = min_n)) +
  geom_line(alpha = 0.5, linewidth = 1.5) +
  geom_point() +
  labs(y = "AUC")
```

Our best model has `min_n` of `r select_best(rf_tune_res, "roc_auc")$min_n` and `mtry` of `r select_best(rf_tune_res, "roc_auc")$mtry`. 

```{r}
best_auc <- select_best(rf_tune_res, "roc_auc")

final_rf <- finalize_model(
  rf_tune,
  best_auc
)

final_rf

```

Check out variable importance

```{r}
final_rf %>%
  set_engine("ranger", importance = "permutation") %>%
  fit(pro_biodiversity ~ .,
    data = train_data_s %>% select(-id)
  ) %>%
  vip(geom = "point")
```

Alturism is pretty high!

`last_fit` fits a final model on the entire training set and evaluates on the testing set.

```{r}
final_wf <- workflow() %>%
  add_recipe(rf_recipe) %>%
  add_model(final_rf)

final_res <- final_wf %>%
  last_fit(data_split)

final_res %>%
  collect_metrics()
```

```{r}
final_res$.predictions %>% 
  as.data.frame() %>% 
  roc_curve(pro_biodiversity, .pred_0) %>% 
  ggplot(aes(x = 1 - specificity, y = sensitivity)) + 
  geom_path(lwd = 1.5, alpha = 0.8) +
  geom_abline(lty = 3) + 
  coord_equal()
```

OK still bad! Let's build a t-learner!

## T-learner

1. separate out the with/without treatment groups from the training data and train 2 models
2. then use each of those models to predict the outcome for the full test dataset
3. the ITE is prediction with treatment - prediction without treatment

```{r}
train_1 <- train_data_s %>%
  filter(recent_nature == 1)

train_0 <- train_data_s %>%
  filter(recent_nature == 0)
```

### treatment == 1

Rather than fitting an initial model this time, I'll go straight into tuning hyperparameters.

```{r}
rf_recipe <- recipe(data = train_1,
                    formula = pro_biodiversity ~
                      income + childhood_nature  + gender  + 
                      education_level + urban + altruism)

rf_workflow <- workflow() %>%
  add_recipe(rf_recipe) %>%
  add_model(rf_tune)

# create a set of cross-validation resamples to use for tuning
trees_folds <- vfold_cv(train_data_s, v = 25)

rf_tune_res_t1 <- 
  tune_grid(rf_workflow,
            resamples = trees_folds,
            grid = tree_grid,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(roc_auc))

```

```{r}
best_auc_t1 <- select_best(rf_tune_res_t1, "roc_auc")

final_rf_t1 <- finalize_model(
  rf_tune,
  best_auc_t1
)

final_rf_t1

```

Choose the model with the best hyperparameters and fit it on the test data where treatment == 1

```{r}
wf_t1 <- workflow() %>%
  add_recipe(rf_recipe) %>%
  add_model(final_rf_t1)

t1_fit <- fit(wf_t1, train_1)

```

### treatment == 0

Tune

```{r}
rf_recipe <- recipe(data = train_0,
                    formula = pro_biodiversity ~ 
                      income + childhood_nature  + gender  + 
                      education_level + urban + altruism)

rf_workflow <- workflow() %>%
  add_recipe(rf_recipe) %>%
  add_model(rf_tune)

# create a set of cross-validation resamples to use for tuning
trees_folds <- vfold_cv(train_data_s, v = 25)

rf_tune_res_t0 <- 
  tune_grid(rf_workflow,
            resamples = trees_folds,
            grid = tree_grid,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(roc_auc))

```

```{r}
best_auc_t0 <- select_best(rf_tune_res_t0, "roc_auc")

final_rf_t0 <- finalize_model(
  rf_tune,
  best_auc_t0
)

final_rf_t0

```
Choose the model with the best hyperparameters and fit it on the test data where treatment == 0

```{r}
wf_t0 <- workflow() %>%
  add_recipe(rf_recipe) %>%
  add_model(final_rf_t0)

t0_fit <- fit(wf_t0, train_0)
```

## Fit t-learner

Now that we have 2 models, one trained on 0 data and one trained on 1 data. Next we need to make predictions for the test dataset using each of the models.

I think to generate the ITEs from a t-learner we need to generate a 2 datasets from the test data: one where we force the treatment to = 1, and one dataset where we force the treatment to = 0. 
Then, make predictions using the relevant model.
Then, we calculate ITEs as prediction with treatment - prediction without treatment.

```{r}
test_data_s %>% 
  mutate(recent_nature = factor(0)) -> test_0

test_data_s %>% 
  mutate(recent_nature = factor(1)) -> test_1

predict(t0_fit, test_0) %>% 
  cbind(test_data_s) %>% 
  mutate(.pred_class = 
           as.numeric(levels(.pred_class))[.pred_class]) %>% 
  rename(pred_0 = .pred_class) -> pred_0_t

predict(t1_fit, test_1) %>% 
  cbind(test_data_s) %>% 
  mutate(.pred_class = 
           as.numeric(levels(.pred_class))[.pred_class]) %>% 
  rename(pred_1 = .pred_class) -> pred_1_t

pred_0_t %>% 
  inner_join(pred_1_t) %>% 
  mutate(t_learner_ite = pred_1 - pred_0) %>% 
  mutate(t_learner_ite = as.factor(t_learner_ite)) -> tlearn_ites

```

## Get s-learner ITEs

Use s-learner model to predict for both 0 and 1 test datasets

```{r}
s_fit <- fit(final_wf, train_data_s)

predict(s_fit, test_0) %>% 
  cbind(test_data_s) %>% 
  mutate(.pred_class = 
           as.numeric(levels(.pred_class))[.pred_class]) %>% 
  rename(pred_0 = .pred_class) -> pred_0_s

predict(s_fit, test_1) %>% 
  cbind(test_data_s) %>% 
  mutate(.pred_class = 
           as.numeric(levels(.pred_class))[.pred_class]) %>% 
  rename(pred_1 = .pred_class) -> pred_1_s

pred_0_s %>% 
  inner_join(pred_1_s) %>% 
  mutate(s_learner_ite = pred_1 - pred_0) %>% 
  mutate(s_learner_ite = as.factor(s_learner_ite)) -> slearn_ites


```

## Compare ITEs

Because this is a classification problem we can use a confusion matrix to compare ITEs

```{r warning=FALSE}
slearn_ites %>% 
  inner_join(tlearn_ites, 
             by = c("id", "pro_biodiversity", "income", "childhood_nature", "gender",
                   "education_level", "urban", "altruism")) -> s_t_preds

conf_mat(
  data = s_t_preds,
  truth = s_learner_ite,
  estimate = t_learner_ite,
  dnn = c("t-learner", "s-learner"),
  case_weights = NULL
) -> cm

autoplot(cm, type = "heatmap")

```

Diagonal is where they agree - both predict the same response.

S-learner looks like it is more conservative, often predicts 0 where t-learner predicts 1.

Can we look at these differences across predictors?


```{r}
s_t_preds %>% 
  mutate(t_learner_ite = 
           as.numeric(levels(t_learner_ite))[t_learner_ite]) %>% 
  group_by(childhood_nature) %>% 
  summarise(t_learner_ite_av = mean(t_learner_ite)) %>% 
  ggplot() +
  geom_col(aes(x = childhood_nature, y = t_learner_ite_av)) +
  ggtitle("t-learner") -> t_childhood_nature

s_t_preds %>% 
  mutate(s_learner_ite = 
           as.numeric(levels(s_learner_ite))[s_learner_ite]) %>% 
  group_by(childhood_nature) %>% 
  summarise(s_learner_ite_av = mean(s_learner_ite)) %>% 
  ggplot() +
  geom_col(aes(x = childhood_nature, y = s_learner_ite_av)) +
  ggtitle("s-learner") -> s_childhood_nature

t_childhood_nature + s_childhood_nature

```


```{r}
s_t_preds %>% 
  mutate(t_learner_ite = 
           as.numeric(levels(t_learner_ite))[t_learner_ite]) %>% 
  group_by(gender) %>% 
  summarise(t_learner_ite_av = mean(t_learner_ite)) %>% 
  ggplot() +
  geom_col(aes(x = gender, y = t_learner_ite_av)) +
  ggtitle("t-learner") -> t_gender

s_t_preds %>% 
  mutate(s_learner_ite = 
           as.numeric(levels(s_learner_ite))[s_learner_ite]) %>% 
  group_by(gender) %>% 
  summarise(s_learner_ite_av = mean(s_learner_ite)) %>% 
  ggplot() +
  geom_col(aes(x = gender, y = s_learner_ite_av)) +
  ggtitle("s-learner") -> s_gender

t_gender + s_gender

```

```{r}
s_t_preds %>% 
  mutate(t_learner_ite = 
           as.numeric(levels(t_learner_ite))[t_learner_ite]) %>% 
  group_by(urban) %>% 
  summarise(t_learner_ite_av = mean(t_learner_ite)) %>% 
  ggplot() +
  geom_col(aes(x = urban, y = t_learner_ite_av)) +
  ggtitle("t-learner") -> t_urban

s_t_preds %>% 
  mutate(s_learner_ite = 
           as.numeric(levels(s_learner_ite))[s_learner_ite]) %>% 
  group_by(urban) %>% 
  summarise(s_learner_ite_av = mean(s_learner_ite)) %>% 
  ggplot() +
  geom_col(aes(x = urban, y = s_learner_ite_av)) +
  ggtitle("s-learner") -> s_urban

t_urban + s_urban

```


```{r}
s_t_preds %>%
  mutate(t_learner_ite = 
           as.numeric(levels(t_learner_ite))[t_learner_ite]) %>% 
  ggplot(aes(x = pro_biodiversity, y = altruism, colour = t_learner_ite)) +
  geom_jitter(alpha = 0.5 ) +
  scale_color_gradient2() +
  ggtitle("t-learner") +
  theme(panel.background = element_rect(fill = "lightgrey")) -> t_urban

s_t_preds %>%
  mutate(s_learner_ite = 
           as.numeric(levels(s_learner_ite))[s_learner_ite]) %>% 
  ggplot(aes(x = pro_biodiversity, y = altruism, colour = s_learner_ite)) +
  geom_jitter(alpha = 0.5 ) +
  scale_color_gradient2() +
  ggtitle("t-learner")  +
  theme(panel.background = element_rect(fill = "lightgrey")) -> s_urban

t_urban + s_urban

```

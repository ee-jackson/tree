---
title: "Fit the meta-meta model and explore preliminary results"
author: '`r Sys.getenv("USER")`'
date: '`r format(Sys.time(), "%d %B, %Y")`' 
always_allow_html: true
output: 
  github_document:
    keep_html: true
---
	
```{r setup, include = FALSE}
file_name <- rstudioapi::getSourceEditorContext()$path

knitr::opts_chunk$set(
  fig.path =
    paste0("figures/", sub("\\.Rmd$", "", basename(file_name)), "/", sep = "")
)

ggplot2::theme_set(ggplot2::theme_classic(base_size = 10))
```

```{r packages, message=FALSE, warning=FALSE}
library("tidyverse")
library("here")
library("tidymodels")
library("vip")
library("patchwork")

set.seed(123)

```

Import the median ITE prediction errors 
(generated by [get-ite-predictions.R](/code/scripts/get-ite-predictions.R))

```{r}
ml_results <- readRDS(here("data", "derived", "results.rds"))

ml_out <- readRDS(here("data", "derived", "model_out.rds"))

glimpse(ml_results)
```

I'm just going to do a quick glm for curiosity's sake.

```{r}
glm(median_error ~ learner * 
      n_train * 
      proportion_not_treated *
      assignment *
      var_omit, 
    ml_results, family = gaussian) -> glm_out

summary(glm_out)
```

## Fit random forest

### train test split 

```{r}
data_split <- initial_split(ml_results, prop = 1/3)
train_data <- training(data_split)
test_data <- testing(data_split)
```

### tune hyperparameters

```{r}
rf_tune <- rand_forest(mtry = tune(), min_n = tune()) %>%
  set_engine("ranger", num.threads = 3) %>%
  set_mode("regression")

tree_grid <- grid_regular(mtry(c(1, 5)),
                          min_n(),
                          levels = 5)

rf_recipe <- recipe(median_error ~ 
                      assignment + proportion_not_treated + 
                      n_train + learner + var_omit,
    data = train_data)

rf_workflow <- workflow() %>%
  add_recipe(rf_recipe) %>%
  add_model(rf_tune)

# create a set of cross-validation resamples to use for tuning
trees_folds <- vfold_cv(train_data, v = 25)

rf_tune_res <- 
  tune_grid(rf_workflow,
            resamples = trees_folds,
            grid = tree_grid,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(rmse))

best_auc <- select_best(rf_tune_res, "rmse")

final_rf <- finalize_model(
  rf_tune,
  best_auc
)

final_rf
```

### vip

```{r}
final_rf %>%
  set_engine("ranger", importance = "permutation") %>%
  fit(median_error ~ .,
    data = ml_results %>% select(-test_id)
  ) %>%
  vip(geom = "point", aesthetics = list(size = 3)) +
  theme_classic(base_size = 20)
```

### fit model

```{r}
final_wf <- workflow() %>%
  add_recipe(rf_recipe) %>%
  add_model(final_rf)

final_res <- final_wf %>%
  last_fit(data_split)

final_res %>%
  collect_metrics()

# final_res %>%
#   collect_predictions()
```

## Visualise!

```{r}
plot_panels <- function(meta_learner, x_var, data) {
  data %>% 
    filter(learner == meta_learner) %>% 
    ggplot(aes(y = .data$median_error, x = .data[[x_var]], 
               colour = .data$n_train, shape = .data$assignment)) +
    geom_jitter(width = 0.1, alpha = 0.7, size = 1) +
    ylim(-3, 6) +
    scale_color_viridis_c() +
    geom_hline(yintercept = 0, colour = "red", linewidth = 0.1, linetype = 2) +
    theme_classic(base_size = 8) +
    guides(color = "none", shape = "none")
}

keys <- expand.grid(
  meta_learner = c("s", "t", "x"),
  x_var = c("assignment", "proportion_not_treated", "n_train", "var_omit")
  ) %>% 
  mutate(x_var = as.character(x_var)) %>% 
  arrange(meta_learner)

purrr::pmap(list(meta_learner = keys$meta_learner,
          x_var = keys$x_var), plot_panels, data = ml_results) -> plot_list

patchwork::wrap_plots(plot_list)

```

First row is s, then t, then x.

```{r}
# plot_panels_all <- function(meta_learner, x_var, data) {
#   data %>% 
#     filter(learner == meta_learner) %>% 
#     ggplot(aes(y = .data$diff, x = .data[[x_var]], 
#                colour = .data$n_train, shape = .data$assignment)) +
#     geom_jitter(width = 0.1, alpha = 0.5, size = 0.5) +
#     ylim(-30, 30) +
#     scale_color_viridis_c() +
#     geom_hline(yintercept = 0, colour = "red", linewidth = 0.1, linetype = 2) +
#     theme_classic(base_size = 6) +
#     guides(color = "none")
# }
#   
# purrr::pmap(list(meta_learner = keys$meta_learner,
#           x_var = keys$x_var), plot_panels_all, data = unnest(ml_out, df_out)) -> plot_list
# 
# patchwork::wrap_plots(plot_list)
```


```{r warning=FALSE, fig.height=12, fig.width=4}

ml_out %>% 
  filter(learner == "s",
         assignment == "random", proportion_not_treated == 0.5,
         n_train == 1600, var_omit == FALSE) %>% 
  mutate(rep = 1:3) %>% 
  unnest(df_out) %>%
  ggplot() +
  geom_hline(yintercept = 0, colour = "grey", linetype = 2) +
  geom_vline(xintercept = 0, colour = "grey", linetype = 2) +
  geom_point(aes(x = cate_real, y = cate_s_learn, colour = abs(diff))) +
  geom_abline(intercept = 0, slope = 1, colour = "blue") +
  scale_color_gradient(low = "lightblue", high = "red3",
                       limits = c(0, 30)) +
  xlim(-30, 30) +
  ylim(-30, 30) +
  ggtitle("S-learner") -> p1

ml_out %>% 
  filter(learner == "t",
         assignment == "random", proportion_not_treated == 0.5,
         n_train == 1600, var_omit == FALSE) %>% 
  mutate(rep = 1:3) %>% 
  unnest(df_out) %>%
  ggplot() +
  geom_hline(yintercept = 0, colour = "grey", linetype = 2) +
  geom_vline(xintercept = 0, colour = "grey", linetype = 2) +
  geom_point(aes(x = cate_real, y = cate_t_learn, colour = abs(diff))) +
  geom_abline(intercept = 0, slope = 1, colour = "blue") +
  scale_color_gradient(low = "lightblue", high = "red3",
                       limits = c(0, 30)) +
  xlim(-30, 30) +
  ylim(-30, 30) +
  ggtitle("T-learner") -> p2


ml_out %>% 
  filter(learner == "x",
         assignment == "random", proportion_not_treated == 0.5,
         n_train == 1600, var_omit == FALSE) %>% 
  mutate(rep = 1:3) %>% 
  unnest(df_out) %>%
  ggplot() +
  geom_hline(yintercept = 0, colour = "grey", linetype = 2) +
  geom_vline(xintercept = 0, colour = "grey", linetype = 2) +
  geom_point(aes(x = cate_real, y = cate_x_learn, colour = abs(diff))) +
  geom_abline(intercept = 0, slope = 1, colour = "blue") +
  scale_color_gradient(low = "lightblue", high = "red3",
                       limits = c(0, 30)) +
  xlim(-30, 30) +
  ylim(-30, 30) +
  ggtitle("X-learner") -> p3

p1 / p2 / p3 +
  plot_layout(guides = "collect") +
  plot_annotation(title = "Sample size = 1600")
```

```{r warning=FALSE, fig.height=12, fig.width=4}

ml_out %>% 
  filter(learner == "s",
         assignment == "random", proportion_not_treated == 0.5,
         n_train == 100, var_omit == FALSE) %>% 
  mutate(rep = 1:3) %>% 
  unnest(df_out) %>%
  ggplot() +
  geom_hline(yintercept = 0, colour = "grey", linetype = 2) +
  geom_vline(xintercept = 0, colour = "grey", linetype = 2) +
  geom_point(aes(x = cate_real, y = cate_s_learn, colour = abs(diff))) +
  geom_abline(intercept = 0, slope = 1, colour = "blue") +
  scale_color_gradient(low = "lightblue", high = "red3",
                       limits = c(0, 30)) +
  xlim(-30, 30) +
  ylim(-30, 30) +
  ggtitle("S-learner") -> p4

ml_out %>% 
  filter(learner == "t",
         assignment == "random", proportion_not_treated == 0.5,
         n_train == 100, var_omit == FALSE) %>% 
  mutate(rep = 1:3) %>% 
  unnest(df_out) %>%
  ggplot() +
  geom_hline(yintercept = 0, colour = "grey", linetype = 2) +
  geom_vline(xintercept = 0, colour = "grey", linetype = 2) +
  geom_point(aes(x = cate_real, y = cate_t_learn, colour = abs(diff))) +
  geom_abline(intercept = 0, slope = 1, colour = "blue") +
  scale_color_gradient(low = "lightblue", high = "red3",
                       limits = c(0, 30)) +
  xlim(-30, 30) +
  ylim(-30, 30) +
  ggtitle("T-learner") -> p5


ml_out %>% 
  filter(learner == "x",
         assignment == "random", proportion_not_treated == 0.5,
         n_train == 100, var_omit == FALSE) %>% 
  mutate(rep = 1:3) %>% 
  unnest(df_out) %>%
  ggplot() +
  geom_hline(yintercept = 0, colour = "grey", linetype = 2) +
  geom_vline(xintercept = 0, colour = "grey", linetype = 2) +
  geom_point(aes(x = cate_real, y = cate_x_learn, colour = abs(diff))) +
  geom_abline(intercept = 0, slope = 1, colour = "blue") +
  scale_color_gradient(low = "lightblue", high = "red3",
                       limits = c(0, 30)) +
  xlim(-30, 30) +
  ylim(-30, 30) +
  ggtitle("X-learner") -> p6

p4 / p5 / p6 +
  plot_layout(guides = "collect") +
  plot_annotation(title = "Sample size = 100")
  
```


```{r warning=FALSE, fig.height=12, fig.width=4}

ml_out %>% 
  filter(learner == "s",
         assignment == "random", proportion_not_treated == 0.75,
         n_train == 1600, var_omit == FALSE) %>% 
  mutate(rep = 1:3) %>% 
  unnest(df_out) %>%
  ggplot() +
  geom_hline(yintercept = 0, colour = "grey", linetype = 2) +
  geom_vline(xintercept = 0, colour = "grey", linetype = 2) +
  geom_point(aes(x = cate_real, y = cate_s_learn, colour = abs(diff))) +
  geom_abline(intercept = 0, slope = 1, colour = "blue") +
  scale_color_gradient(low = "lightblue", high = "red3",
                       limits = c(0, 30)) +
  xlim(-30, 30) +
  ylim(-30, 30) +
  ggtitle("S-learner") -> p7

ml_out %>% 
  filter(learner == "t",
         assignment == "random", proportion_not_treated == 0.75,
         n_train == 1600, var_omit == FALSE) %>% 
  mutate(rep = 1:3) %>% 
  unnest(df_out) %>%
  ggplot() +
  geom_hline(yintercept = 0, colour = "grey", linetype = 2) +
  geom_vline(xintercept = 0, colour = "grey", linetype = 2) +
  geom_point(aes(x = cate_real, y = cate_t_learn, colour = abs(diff))) +
  geom_abline(intercept = 0, slope = 1, colour = "blue") +
  scale_color_gradient(low = "lightblue", high = "red3",
                       limits = c(0, 30)) +
  xlim(-30, 30) +
  ylim(-30, 30) +
  ggtitle("T-learner") -> p8


ml_out %>% 
  filter(learner == "x",
         assignment == "random", proportion_not_treated == 0.75,
         n_train == 1600, var_omit == FALSE) %>% 
  mutate(rep = 1:3) %>% 
  unnest(df_out) %>%
  ggplot() +
  geom_hline(yintercept = 0, colour = "grey", linetype = 2) +
  geom_vline(xintercept = 0, colour = "grey", linetype = 2) +
  geom_point(aes(x = cate_real, y = cate_x_learn, colour = abs(diff))) +
  geom_abline(intercept = 0, slope = 1, colour = "blue") +
  scale_color_gradient(low = "lightblue", high = "red3",
                       limits = c(0, 30)) +
  xlim(-30, 30) +
  ylim(-30, 30) +
  ggtitle("X-learner") -> p9

p7 / p8 / p9 +
  plot_layout(guides = "collect") +
  plot_annotation(title = "75% not treated")
```

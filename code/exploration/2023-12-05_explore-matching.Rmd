---
title: "Matching"
author: '`r Sys.getenv("USER")`'
date: '`r format(Sys.time(), "%d %B, %Y")`' 
always_allow_html: true
output: 
  github_document:
    keep_html: true
---
	
```{r setup, include = FALSE}
file_name <- rstudioapi::getSourceEditorContext()$path

knitr::opts_chunk$set(
  fig.path =
    paste0("figures/", sub("\\.Rmd$", "", basename(file_name)), "/", sep = "")
)

ggplot2::theme_set(ggplot2::theme_classic(base_size = 10))
```

__'We define “matching” broadly to be any method that aims to equate (or “balance”) the distribution of covariates in the treated and control groups.' [(Stuart 2010)](https://doi.org/10.1214%2F09-STS313)__

We want to test the effect that matching your training data might have on predictions of the ITE.

In this notebook I'm going to explore what [{MatchIt}](https://kosukeimai.github.io/MatchIt/) 
has to offer and learn how to use it.

```{r packages, message=FALSE, warning=FALSE}
library("tidyverse")
library("here")
library("MatchIt")
library("tidymodels")
set.seed(123)
```

# Prep data

```{r}
data <- 
  readRDS(here::here("data", "derived", "ForManSims_RCP0_same_time_clim.rds"))
```

## Select spruce dominated plots only

```{r}
data %>% 
  filter(period == 0) %>% 
  mutate(prop_pine = volume_pine/ standing_volume) %>% 
  filter(prop_pine >= 0.5) %>% 
  select(description) -> spruce_dom_plots

data %>% 
  filter(description %in% spruce_dom_plots$description) -> data_spruce 
```

## Assign plots to a realised management regime

Random assignment where set aside is not treated (0) and BAU is treated (1).

```{r}
data_spruce %>% 
    select(description) %>% 
    distinct() -> id_list

id_list %>% 
  slice_sample(prop = 0.5) -> treat_ids

data_spruce %>%
  mutate(tr =
           case_when(description %in% treat_ids$description ~ 1,
                     .default = 0)) -> data_assigned

```

## Select features 

```{r}
data_assigned %>%
  filter(period == 0) %>%
  select(
    description,
    soil_moist_code,
    altitude, mat, map, ditch, no_of_stems, volume_pine, volume_spruce,
    volume_birch, volume_aspen, volume_oak, volume_beech, 
    volume_southern_broadleaf, volume_larch
  ) -> features

data_assigned %>% 
  select(description, tr, control_category_name, total_soil_carbon) %>% 
  pivot_wider(id_cols = c(description, tr), names_from = control_category_name, values_from = total_soil_carbon) %>% 
  mutate(soil_carbon_obs = case_when(tr == 0 ~ `SetAside (Unmanaged)`,
                                tr == 1 ~ `BAU - NoThinning`)) %>% 
  rename(soil_carbon_initial = `Initial state`,
         soil_carbon_0 = `SetAside (Unmanaged)`, 
         soil_carbon_1 = `BAU - NoThinning`) %>% 
  left_join(features) -> data_obs
```

## Test and train

```{r}
data_split <- initial_split(data_obs, prop = 1/3)
train_data <- training(data_split)
test_data <- testing(data_split)
```

# Matching

Following [this vignette](https://kosukeimai.github.io/MatchIt/articles/MatchIt.html).

## Check Initial Imbalance

Usually the method argument specifies the method of matching to be performed. 
Here, we set it to NULL so we can assess balance prior to matching.

```{r}
out_initial <-
  matchit(
    tr ~ soil_carbon_initial + altitude + mat + map + soil_moist_code + ditch +
      no_of_stems + volume_pine + volume_spruce + volume_birch + volume_aspen + 
      volume_oak + volume_beech + volume_southern_broadleaf + volume_larch,
    data = train_data,
    method = NULL,
    distance = "glm"
  )

summary(out_initial)

plot(summary(out_initial))
```

Smaller values for `Std. Mean Diff.` indicate better balance, `eCDF Mean` and `eCDF Max` should be close to zero with `Var. Ratio` close to one.

It looks like `mat` is the most unbalanced. 

```{r}
ggplot(train_data) +
  geom_density(aes(x = mat, 
                   fill = as.factor(tr), 
                   group = as.factor(tr)), 
               alpha = 0.6)
```

Looks quite well matched to me.. but not perfect. 
Let's see what matching does.

## Matching

Now we set the `method` to the matching method we want. 
[There are several](https://kosukeimai.github.io/MatchIt/articles/matching-methods.html#matching-methods) to choose from...

_"The criteria on which a matching specification should be judged are balance and remaining (effective) sample size after matching."_

_"If the target of inference is the ATE, optimal or generalized full matching, subclassification, or profile matching can be used."_

_"For large datasets, neither optimal full matching nor profile matching may be possible, in which case generalised full matching and subclassification are faster solutions."_

It seems like optimal full matching would be best 
([`method = "full"`](https://kosukeimai.github.io/MatchIt/articles/matching-methods.html#optimal-full-matching-method-full)), 
but if it's too slow we could go for generalised full matching 
([`method = "quick"`](https://kosukeimai.github.io/MatchIt/articles/matching-methods.html#generalized-full-matching-method-quick)). 

```{r}
out_matched <-
  matchit(
    tr ~ soil_carbon_initial + altitude + mat + map + soil_moist_code + ditch +
      no_of_stems + volume_pine + volume_spruce + volume_birch + volume_aspen + 
      volume_oak + volume_beech + volume_southern_broadleaf + volume_larch,
    data = train_data,
    method = "full",
    distance = "glm",
    estimand = "ATE"
  )

print(out_matched)

summary(out_matched, un = FALSE)

plot(summary(out_matched))
```

## Assessing the Quality of Matches

```{r}
plot(out_matched, type = "jitter", interactive = FALSE)
```

We don't have any unmatched units, 
I think this is due to the kind of matching we're doing?

```{r}
plot(out_matched, type = "density", interactive = FALSE,
     which.xs = ~ mat + map + soil_carbon_initial)
```

I can't see a big difference, 
but they have moved a little.
I guess the treatment groups were already quite well matched.

We can extract the matched data.

```{r}
matched_data <- match.data(out_matched)

glimpse(matched_data)
```

`distance`, `weights` and `subclass` columns have been added to the data.
When we model the data, we need to include the matching weights in the estimation - 
they can be used like propensity scores. 

_"The primary output of full matching is a set of matching weights that can be applied to the matched sample; in this way, full matching can be seen as a robust alternative to propensity score weighting, robust in the sense that the propensity score model does not need to be correct to estimate the treatment effect without bias."_

`distance` is the propensity score and 
`weights` is the probability of a non-treated plot being treated or
the probability of a treated plot not being treated.

We do this because _"If [a treated individual] has a low probability of treatment, that individual looks like the untreated. However, [it] was treated. This must be interesting. We have a treated that looks like the untreated, so we will give that entity a high weight."_ (Causal Inference for the Brave and True, [Source](https://www.franciscoyira.com/post/matching-in-r-3-propensity-score-iptw/))

To achieve common support we need to have treatment and control units across the propensity score range,
and to estimate the ATE, 
the distributions of propensity scores for the treated and untreated units should completely overlap.

```{r}
ggplot(matched_data) +
  geom_density(aes(x = distance, 
                   group = as.factor(tr), 
                   fill = as.factor(tr)),
               alpha = 0.6) +
  xlim(0,1)
```

Looks good, for every value of `distance` (propensity score), 
there are both treated and untreated plots.

# Fit model

I was going to try and fit a t-learner using the weights/propensity scores,
but I can't see how to include these in the models.
Then I realised... isn't that what the X-learner does? 
The X-learner adjusts the predicted treatment effects by the propensity scores to estimate CATEs.

So, I think I must be using the wrong kind of matching method.
I guess we want a method that removes plots that can't be matched / don't have overlap.
